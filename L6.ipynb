{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfoOUvgU_RdM",
        "outputId": "453d4b05-ae10-4d56-9422-9be33bbea0e3"
      },
      "source": [
        "!pip install nltk snowballstemmer pymorphy2 pymystem3 gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: snowballstemmer in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymystem3 in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 2.1MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pymystem3) (2.23.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3) (1.24.3)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqGfuRoVFGm8",
        "outputId": "90c3e5aa-951d-4aba-df37-89b8d7bacd91"
      },
      "source": [
        "try:\r\n",
        "    from google.colab import drive\r\n",
        "    import os\r\n",
        "    drive.mount('/content/drive')\r\n",
        "    os.chdir('/content/drive/My Drive/6_laba/')\r\n",
        "except ImportError:\r\n",
        "    pass"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YFUHfd-Gdfk"
      },
      "source": [
        "# **Предобработка текстов**\r\n",
        "Поскольку в русском языке много словоформ, прежде всего нужно преобразовать все тексты к единому виду.\r\n",
        "\r\n",
        "Считаем один из файлов и посмотрим, что мы можем с ним сделать"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "HTGFc9reGNm8",
        "outputId": "a3b7fc5c-a9a4-47a2-d0e8-e7faf5833fa9"
      },
      "source": [
        "with open(\"Onegin/oneg_1.txt\", encoding=\"utf8\") as f:\r\n",
        "    example_text = f.read()\r\n",
        "\r\n",
        "example_text"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nHe мысля гордый свет забавить,\\n\\nВниманье дружбы возлюбя,\\n\\nХотел бы я тебе представить\\n\\nЗалог достойнее тебя,\\n\\nДостойнее души прекрасной,\\n\\nСвятой исполненной мечты,\\n\\nПоэзии живой и ясной,\\n\\nВысоких дум и простоты;\\n\\nНо так и быть – рукой пристрастной\\n\\nПрими собранье пестрых глав,\\n\\nПолусмешных, полупечальных,\\n\\nПростонародных, идеальных,\\n\\nНебрежный плод моих забав,\\n\\nБессонниц, легких вдохновений,\\n\\nНезрелых и увядших лет,\\n\\nУма холодных наблюдений\\n\\nИ сердца горестных замет.\\n\\n\\n\\n\\n\\nГлава первая\\n\\n\\n\\n\\nИ жить торопится, и чувствовать спешит.\\n\\nКнязь Вяземский[2]\\n\\n\\n\\n\\n\\nI\\n\\n\\n\\n\\n«Мой дядя самых честных правил,\\n\\nКогда не в шутку занемог,\\n\\nОн уважать себя заставил\\n\\nИ лучше выдумать не мог.\\n\\nЕго пример другим наука;\\n\\nНо, боже мой, какая скука\\n\\nС больным сидеть и день и ночь,\\n\\nНе отходя ни шагу прочь!\\n\\nКакое низкое коварство\\n\\nПолуживого забавлять,\\n\\nЕму подушки поправлять,\\n\\nПечально подносить лекарство,\\n\\nВздыхать и думать про себя:\\n\\nКогда же черт возьмет тебя!»\\n\\n\\n\\n\\n\\nII\\n\\n\\n\\n\\nТак думал молодой повеса,\\n\\nЛетя в пыли на почтовых,\\n\\nВсевышней волею Зевеса\\n\\nНаследник всех своих родных. —\\n\\nДрузья Людмилы и Руслана!\\n\\nС героем моего романа\\n\\nБез предисловий, сей же час\\n\\nПозвольте познакомить вас:\\n\\nОнегин, добрый мой приятель,\\n\\nРодился на брегах Невы,\\n\\nГде, может быть, родились вы\\n\\nИли блистали, мой читатель;\\n\\nТам некогда гулял и я:\\n\\nНо вреден север для меня.[3]\\n\\n\\n\\n\\n\\nIII\\n\\n\\n\\n\\nСлужив отлично-благородно,\\n\\nДолгами жил его отец,\\n\\nДавал три бала ежегодно\\n\\nИ промотался наконец.\\n\\nСудьба Евгения хранила:\\n\\nСперва Madame за ним ходила,\\n\\nПотом Monsieur ее сменил;\\n\\nРебенок был резов, но мил.\\n\\nMonsieur l’Abbé, француз убогой,\\n\\nЧтоб не измучилось дитя,\\n\\nУчил его всему шутя,\\n\\nНе докучал моралью строгой,\\n\\nСлегка за шалости бранил\\n\\nИ в Летний сад гулять водил.\\n\\n\\n\\n\\n\\nIV\\n\\n\\n\\n\\nКогда же юности мятежной\\n\\nПришла Евгению пора,\\n\\nПора надежд и грусти нежной,\\n\\nMonsieur прогнали со двора.\\n\\nВот мой Онегин на свободе;\\n\\nОстрижен по последней моде;\\n\\nКак dandy[4] лондонский одет —\\n\\nИ наконец увидел свет.\\n\\nОн по-французски совершенно\\n\\nМог изъясняться и писал;\\n\\nЛегко мазурку танцевал\\n\\nИ кланялся непринужденно;\\n\\nЧего ж вам больше? Свет решил,\\n\\nЧто он умен и очень мил.\\n\\n\\n\\n\\n\\nV\\n\\n\\n\\n\\nМы все учились понемногу\\n\\nЧему-нибудь и как-нибудь,\\n\\nТак воспитаньем, слава богу,\\n\\nУ нас немудрено блеснуть.\\n\\nОнегин был, по мненью многих\\n\\n(Судей решительных и строгих),\\n\\nУченый малый, но педант.[5]\\n\\nИмел он счастливый талант\\n\\nБез принужденья в разговоре\\n\\nКоснуться до всего слегка,\\n\\nС ученым видом знатока\\n\\nХранить молчанье в важном споре\\n\\nИ возбуждать улыбку дам\\n\\nОгнем нежданных эпиграмм.\\n\\n\\n\\n\\n\\nVI\\n\\n\\n\\n\\nЛатынь из моды вышла ныне:\\n\\nТак, если правду вам сказать,\\n\\nОн знал довольно по-латыни,\\n\\nЧтоб эпиграфы разбирать,\\n\\nПотолковать об Ювенале,\\n\\nВ конце письма поставить vale,[6]\\n\\nДа помнил, хоть не без греха,\\n\\nИз Энеиды два стиха.\\n\\nОн рыться не имел охоты\\n\\nВ хронологической пыли\\n\\nБытописания земли;\\n\\nНо дней минувших анекдоты,\\n\\nОт Ромула до наших дней,\\n\\nХранил он в памяти своей.\\n\\n\\n\\n\\n\\nVII\\n\\n\\n\\n\\nВысокой страсти не имея\\n\\nДля звуков жизни не щадить,\\n\\nНе мог он ямба от хорея,\\n\\nКак мы ни бились, отличить.\\n\\nБранил Гомера, Феокрита;\\n\\nЗато читал Адама Смита\\n\\nИ был глубокий эконом,\\n\\nТо есть умел судить о том,\\n\\nКак государство богатеет,\\n\\nИ чем живет, и почему\\n\\nНе нужно золота ему,\\n\\nКогда простой продукт имеет.\\n\\nОтец понять его не мог\\n\\nИ земли отдавал в залог.\\n\\n\\n\\n\\n\\nVIII\\n\\n\\n\\n\\nВсего, что знал еще Евгений,\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NiNP9aoGzCs"
      },
      "source": [
        "Токенизация текста - просто выделение оттуда отдельных слов. Обратите внимание, они не приводятся к одному регистру, знаки препинания не удаляются."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suYXsJScGv6y",
        "outputId": "305b1247-f9af-4ad9-f4df-3362a5a40f44"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "tokens = nltk.word_tokenize(example_text)\r\n",
        "tokens"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He',\n",
              " 'мысля',\n",
              " 'гордый',\n",
              " 'свет',\n",
              " 'забавить',\n",
              " ',',\n",
              " 'Вниманье',\n",
              " 'дружбы',\n",
              " 'возлюбя',\n",
              " ',',\n",
              " 'Хотел',\n",
              " 'бы',\n",
              " 'я',\n",
              " 'тебе',\n",
              " 'представить',\n",
              " 'Залог',\n",
              " 'достойнее',\n",
              " 'тебя',\n",
              " ',',\n",
              " 'Достойнее',\n",
              " 'души',\n",
              " 'прекрасной',\n",
              " ',',\n",
              " 'Святой',\n",
              " 'исполненной',\n",
              " 'мечты',\n",
              " ',',\n",
              " 'Поэзии',\n",
              " 'живой',\n",
              " 'и',\n",
              " 'ясной',\n",
              " ',',\n",
              " 'Высоких',\n",
              " 'дум',\n",
              " 'и',\n",
              " 'простоты',\n",
              " ';',\n",
              " 'Но',\n",
              " 'так',\n",
              " 'и',\n",
              " 'быть',\n",
              " '–',\n",
              " 'рукой',\n",
              " 'пристрастной',\n",
              " 'Прими',\n",
              " 'собранье',\n",
              " 'пестрых',\n",
              " 'глав',\n",
              " ',',\n",
              " 'Полусмешных',\n",
              " ',',\n",
              " 'полупечальных',\n",
              " ',',\n",
              " 'Простонародных',\n",
              " ',',\n",
              " 'идеальных',\n",
              " ',',\n",
              " 'Небрежный',\n",
              " 'плод',\n",
              " 'моих',\n",
              " 'забав',\n",
              " ',',\n",
              " 'Бессонниц',\n",
              " ',',\n",
              " 'легких',\n",
              " 'вдохновений',\n",
              " ',',\n",
              " 'Незрелых',\n",
              " 'и',\n",
              " 'увядших',\n",
              " 'лет',\n",
              " ',',\n",
              " 'Ума',\n",
              " 'холодных',\n",
              " 'наблюдений',\n",
              " 'И',\n",
              " 'сердца',\n",
              " 'горестных',\n",
              " 'замет',\n",
              " '.',\n",
              " 'Глава',\n",
              " 'первая',\n",
              " 'И',\n",
              " 'жить',\n",
              " 'торопится',\n",
              " ',',\n",
              " 'и',\n",
              " 'чувствовать',\n",
              " 'спешит',\n",
              " '.',\n",
              " 'Князь',\n",
              " 'Вяземский',\n",
              " '[',\n",
              " '2',\n",
              " ']',\n",
              " 'I',\n",
              " '«',\n",
              " 'Мой',\n",
              " 'дядя',\n",
              " 'самых',\n",
              " 'честных',\n",
              " 'правил',\n",
              " ',',\n",
              " 'Когда',\n",
              " 'не',\n",
              " 'в',\n",
              " 'шутку',\n",
              " 'занемог',\n",
              " ',',\n",
              " 'Он',\n",
              " 'уважать',\n",
              " 'себя',\n",
              " 'заставил',\n",
              " 'И',\n",
              " 'лучше',\n",
              " 'выдумать',\n",
              " 'не',\n",
              " 'мог',\n",
              " '.',\n",
              " 'Его',\n",
              " 'пример',\n",
              " 'другим',\n",
              " 'наука',\n",
              " ';',\n",
              " 'Но',\n",
              " ',',\n",
              " 'боже',\n",
              " 'мой',\n",
              " ',',\n",
              " 'какая',\n",
              " 'скука',\n",
              " 'С',\n",
              " 'больным',\n",
              " 'сидеть',\n",
              " 'и',\n",
              " 'день',\n",
              " 'и',\n",
              " 'ночь',\n",
              " ',',\n",
              " 'Не',\n",
              " 'отходя',\n",
              " 'ни',\n",
              " 'шагу',\n",
              " 'прочь',\n",
              " '!',\n",
              " 'Какое',\n",
              " 'низкое',\n",
              " 'коварство',\n",
              " 'Полуживого',\n",
              " 'забавлять',\n",
              " ',',\n",
              " 'Ему',\n",
              " 'подушки',\n",
              " 'поправлять',\n",
              " ',',\n",
              " 'Печально',\n",
              " 'подносить',\n",
              " 'лекарство',\n",
              " ',',\n",
              " 'Вздыхать',\n",
              " 'и',\n",
              " 'думать',\n",
              " 'про',\n",
              " 'себя',\n",
              " ':',\n",
              " 'Когда',\n",
              " 'же',\n",
              " 'черт',\n",
              " 'возьмет',\n",
              " 'тебя',\n",
              " '!',\n",
              " '»',\n",
              " 'II',\n",
              " 'Так',\n",
              " 'думал',\n",
              " 'молодой',\n",
              " 'повеса',\n",
              " ',',\n",
              " 'Летя',\n",
              " 'в',\n",
              " 'пыли',\n",
              " 'на',\n",
              " 'почтовых',\n",
              " ',',\n",
              " 'Всевышней',\n",
              " 'волею',\n",
              " 'Зевеса',\n",
              " 'Наследник',\n",
              " 'всех',\n",
              " 'своих',\n",
              " 'родных',\n",
              " '.',\n",
              " '—',\n",
              " 'Друзья',\n",
              " 'Людмилы',\n",
              " 'и',\n",
              " 'Руслана',\n",
              " '!',\n",
              " 'С',\n",
              " 'героем',\n",
              " 'моего',\n",
              " 'романа',\n",
              " 'Без',\n",
              " 'предисловий',\n",
              " ',',\n",
              " 'сей',\n",
              " 'же',\n",
              " 'час',\n",
              " 'Позвольте',\n",
              " 'познакомить',\n",
              " 'вас',\n",
              " ':',\n",
              " 'Онегин',\n",
              " ',',\n",
              " 'добрый',\n",
              " 'мой',\n",
              " 'приятель',\n",
              " ',',\n",
              " 'Родился',\n",
              " 'на',\n",
              " 'брегах',\n",
              " 'Невы',\n",
              " ',',\n",
              " 'Где',\n",
              " ',',\n",
              " 'может',\n",
              " 'быть',\n",
              " ',',\n",
              " 'родились',\n",
              " 'вы',\n",
              " 'Или',\n",
              " 'блистали',\n",
              " ',',\n",
              " 'мой',\n",
              " 'читатель',\n",
              " ';',\n",
              " 'Там',\n",
              " 'некогда',\n",
              " 'гулял',\n",
              " 'и',\n",
              " 'я',\n",
              " ':',\n",
              " 'Но',\n",
              " 'вреден',\n",
              " 'север',\n",
              " 'для',\n",
              " 'меня',\n",
              " '.',\n",
              " '[',\n",
              " '3',\n",
              " ']',\n",
              " 'III',\n",
              " 'Служив',\n",
              " 'отлично-благородно',\n",
              " ',',\n",
              " 'Долгами',\n",
              " 'жил',\n",
              " 'его',\n",
              " 'отец',\n",
              " ',',\n",
              " 'Давал',\n",
              " 'три',\n",
              " 'бала',\n",
              " 'ежегодно',\n",
              " 'И',\n",
              " 'промотался',\n",
              " 'наконец',\n",
              " '.',\n",
              " 'Судьба',\n",
              " 'Евгения',\n",
              " 'хранила',\n",
              " ':',\n",
              " 'Сперва',\n",
              " 'Madame',\n",
              " 'за',\n",
              " 'ним',\n",
              " 'ходила',\n",
              " ',',\n",
              " 'Потом',\n",
              " 'Monsieur',\n",
              " 'ее',\n",
              " 'сменил',\n",
              " ';',\n",
              " 'Ребенок',\n",
              " 'был',\n",
              " 'резов',\n",
              " ',',\n",
              " 'но',\n",
              " 'мил',\n",
              " '.',\n",
              " 'Monsieur',\n",
              " 'l',\n",
              " '’',\n",
              " 'Abbé',\n",
              " ',',\n",
              " 'француз',\n",
              " 'убогой',\n",
              " ',',\n",
              " 'Чтоб',\n",
              " 'не',\n",
              " 'измучилось',\n",
              " 'дитя',\n",
              " ',',\n",
              " 'Учил',\n",
              " 'его',\n",
              " 'всему',\n",
              " 'шутя',\n",
              " ',',\n",
              " 'Не',\n",
              " 'докучал',\n",
              " 'моралью',\n",
              " 'строгой',\n",
              " ',',\n",
              " 'Слегка',\n",
              " 'за',\n",
              " 'шалости',\n",
              " 'бранил',\n",
              " 'И',\n",
              " 'в',\n",
              " 'Летний',\n",
              " 'сад',\n",
              " 'гулять',\n",
              " 'водил',\n",
              " '.',\n",
              " 'IV',\n",
              " 'Когда',\n",
              " 'же',\n",
              " 'юности',\n",
              " 'мятежной',\n",
              " 'Пришла',\n",
              " 'Евгению',\n",
              " 'пора',\n",
              " ',',\n",
              " 'Пора',\n",
              " 'надежд',\n",
              " 'и',\n",
              " 'грусти',\n",
              " 'нежной',\n",
              " ',',\n",
              " 'Monsieur',\n",
              " 'прогнали',\n",
              " 'со',\n",
              " 'двора',\n",
              " '.',\n",
              " 'Вот',\n",
              " 'мой',\n",
              " 'Онегин',\n",
              " 'на',\n",
              " 'свободе',\n",
              " ';',\n",
              " 'Острижен',\n",
              " 'по',\n",
              " 'последней',\n",
              " 'моде',\n",
              " ';',\n",
              " 'Как',\n",
              " 'dandy',\n",
              " '[',\n",
              " '4',\n",
              " ']',\n",
              " 'лондонский',\n",
              " 'одет',\n",
              " '—',\n",
              " 'И',\n",
              " 'наконец',\n",
              " 'увидел',\n",
              " 'свет',\n",
              " '.',\n",
              " 'Он',\n",
              " 'по-французски',\n",
              " 'совершенно',\n",
              " 'Мог',\n",
              " 'изъясняться',\n",
              " 'и',\n",
              " 'писал',\n",
              " ';',\n",
              " 'Легко',\n",
              " 'мазурку',\n",
              " 'танцевал',\n",
              " 'И',\n",
              " 'кланялся',\n",
              " 'непринужденно',\n",
              " ';',\n",
              " 'Чего',\n",
              " 'ж',\n",
              " 'вам',\n",
              " 'больше',\n",
              " '?',\n",
              " 'Свет',\n",
              " 'решил',\n",
              " ',',\n",
              " 'Что',\n",
              " 'он',\n",
              " 'умен',\n",
              " 'и',\n",
              " 'очень',\n",
              " 'мил',\n",
              " '.',\n",
              " 'V',\n",
              " 'Мы',\n",
              " 'все',\n",
              " 'учились',\n",
              " 'понемногу',\n",
              " 'Чему-нибудь',\n",
              " 'и',\n",
              " 'как-нибудь',\n",
              " ',',\n",
              " 'Так',\n",
              " 'воспитаньем',\n",
              " ',',\n",
              " 'слава',\n",
              " 'богу',\n",
              " ',',\n",
              " 'У',\n",
              " 'нас',\n",
              " 'немудрено',\n",
              " 'блеснуть',\n",
              " '.',\n",
              " 'Онегин',\n",
              " 'был',\n",
              " ',',\n",
              " 'по',\n",
              " 'мненью',\n",
              " 'многих',\n",
              " '(',\n",
              " 'Судей',\n",
              " 'решительных',\n",
              " 'и',\n",
              " 'строгих',\n",
              " ')',\n",
              " ',',\n",
              " 'Ученый',\n",
              " 'малый',\n",
              " ',',\n",
              " 'но',\n",
              " 'педант',\n",
              " '.',\n",
              " '[',\n",
              " '5',\n",
              " ']',\n",
              " 'Имел',\n",
              " 'он',\n",
              " 'счастливый',\n",
              " 'талант',\n",
              " 'Без',\n",
              " 'принужденья',\n",
              " 'в',\n",
              " 'разговоре',\n",
              " 'Коснуться',\n",
              " 'до',\n",
              " 'всего',\n",
              " 'слегка',\n",
              " ',',\n",
              " 'С',\n",
              " 'ученым',\n",
              " 'видом',\n",
              " 'знатока',\n",
              " 'Хранить',\n",
              " 'молчанье',\n",
              " 'в',\n",
              " 'важном',\n",
              " 'споре',\n",
              " 'И',\n",
              " 'возбуждать',\n",
              " 'улыбку',\n",
              " 'дам',\n",
              " 'Огнем',\n",
              " 'нежданных',\n",
              " 'эпиграмм',\n",
              " '.',\n",
              " 'VI',\n",
              " 'Латынь',\n",
              " 'из',\n",
              " 'моды',\n",
              " 'вышла',\n",
              " 'ныне',\n",
              " ':',\n",
              " 'Так',\n",
              " ',',\n",
              " 'если',\n",
              " 'правду',\n",
              " 'вам',\n",
              " 'сказать',\n",
              " ',',\n",
              " 'Он',\n",
              " 'знал',\n",
              " 'довольно',\n",
              " 'по-латыни',\n",
              " ',',\n",
              " 'Чтоб',\n",
              " 'эпиграфы',\n",
              " 'разбирать',\n",
              " ',',\n",
              " 'Потолковать',\n",
              " 'об',\n",
              " 'Ювенале',\n",
              " ',',\n",
              " 'В',\n",
              " 'конце',\n",
              " 'письма',\n",
              " 'поставить',\n",
              " 'vale',\n",
              " ',',\n",
              " '[',\n",
              " '6',\n",
              " ']',\n",
              " 'Да',\n",
              " 'помнил',\n",
              " ',',\n",
              " 'хоть',\n",
              " 'не',\n",
              " 'без',\n",
              " 'греха',\n",
              " ',',\n",
              " 'Из',\n",
              " 'Энеиды',\n",
              " 'два',\n",
              " 'стиха',\n",
              " '.',\n",
              " 'Он',\n",
              " 'рыться',\n",
              " 'не',\n",
              " 'имел',\n",
              " 'охоты',\n",
              " 'В',\n",
              " 'хронологической',\n",
              " 'пыли',\n",
              " 'Бытописания',\n",
              " 'земли',\n",
              " ';',\n",
              " 'Но',\n",
              " 'дней',\n",
              " 'минувших',\n",
              " 'анекдоты',\n",
              " ',',\n",
              " 'От',\n",
              " 'Ромула',\n",
              " 'до',\n",
              " 'наших',\n",
              " 'дней',\n",
              " ',',\n",
              " 'Хранил',\n",
              " 'он',\n",
              " 'в',\n",
              " 'памяти',\n",
              " 'своей',\n",
              " '.',\n",
              " 'VII',\n",
              " 'Высокой',\n",
              " 'страсти',\n",
              " 'не',\n",
              " 'имея',\n",
              " 'Для',\n",
              " 'звуков',\n",
              " 'жизни',\n",
              " 'не',\n",
              " 'щадить',\n",
              " ',',\n",
              " 'Не',\n",
              " 'мог',\n",
              " 'он',\n",
              " 'ямба',\n",
              " 'от',\n",
              " 'хорея',\n",
              " ',',\n",
              " 'Как',\n",
              " 'мы',\n",
              " 'ни',\n",
              " 'бились',\n",
              " ',',\n",
              " 'отличить',\n",
              " '.',\n",
              " 'Бранил',\n",
              " 'Гомера',\n",
              " ',',\n",
              " 'Феокрита',\n",
              " ';',\n",
              " 'Зато',\n",
              " 'читал',\n",
              " 'Адама',\n",
              " 'Смита',\n",
              " 'И',\n",
              " 'был',\n",
              " 'глубокий',\n",
              " 'эконом',\n",
              " ',',\n",
              " 'То',\n",
              " 'есть',\n",
              " 'умел',\n",
              " 'судить',\n",
              " 'о',\n",
              " 'том',\n",
              " ',',\n",
              " 'Как',\n",
              " 'государство',\n",
              " 'богатеет',\n",
              " ',',\n",
              " 'И',\n",
              " 'чем',\n",
              " 'живет',\n",
              " ',',\n",
              " 'и',\n",
              " 'почему',\n",
              " 'Не',\n",
              " 'нужно',\n",
              " 'золота',\n",
              " 'ему',\n",
              " ',',\n",
              " 'Когда',\n",
              " 'простой',\n",
              " 'продукт',\n",
              " 'имеет',\n",
              " '.',\n",
              " 'Отец',\n",
              " 'понять',\n",
              " 'его',\n",
              " 'не',\n",
              " 'мог',\n",
              " 'И',\n",
              " 'земли',\n",
              " 'отдавал',\n",
              " 'в',\n",
              " 'залог',\n",
              " '.',\n",
              " 'VIII',\n",
              " 'Всего',\n",
              " ',',\n",
              " 'что',\n",
              " 'знал',\n",
              " 'еще',\n",
              " 'Евгений',\n",
              " ',']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsJyt8gMG_It"
      },
      "source": [
        "И теперь посмотрим, как морфоанализатор сможет преобразовать наш исходный текст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaiM1fKnG3W_",
        "outputId": "8c8c52b5-6647-4a2c-818e-01fb61eb140e"
      },
      "source": [
        "import pymorphy2\r\n",
        "morph = pymorphy2.MorphAnalyzer()\r\n",
        "lemm_pymorph = [morph.parse(s)[0].normal_form for s in tokens[:200]]\r\n",
        "lemm_pymorph"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['he',\n",
              " 'мыслить',\n",
              " 'гордый',\n",
              " 'свет',\n",
              " 'забавить',\n",
              " ',',\n",
              " 'внимание',\n",
              " 'дружба',\n",
              " 'возлюбя',\n",
              " ',',\n",
              " 'хотеть',\n",
              " 'бы',\n",
              " 'я',\n",
              " 'ты',\n",
              " 'представить',\n",
              " 'залог',\n",
              " 'достойный',\n",
              " 'ты',\n",
              " ',',\n",
              " 'достойный',\n",
              " 'душа',\n",
              " 'прекрасный',\n",
              " ',',\n",
              " 'святой',\n",
              " 'исполнить',\n",
              " 'мечта',\n",
              " ',',\n",
              " 'поэзия',\n",
              " 'живой',\n",
              " 'и',\n",
              " 'ясный',\n",
              " ',',\n",
              " 'высокий',\n",
              " 'дума',\n",
              " 'и',\n",
              " 'простота',\n",
              " ';',\n",
              " 'но',\n",
              " 'так',\n",
              " 'и',\n",
              " 'быть',\n",
              " '–',\n",
              " 'рука',\n",
              " 'пристрастный',\n",
              " 'принять',\n",
              " 'собрание',\n",
              " 'пёстрый',\n",
              " 'глава',\n",
              " ',',\n",
              " 'полусмешной',\n",
              " ',',\n",
              " 'полупечальный',\n",
              " ',',\n",
              " 'простонародный',\n",
              " ',',\n",
              " 'идеальный',\n",
              " ',',\n",
              " 'небрежный',\n",
              " 'плод',\n",
              " 'мой',\n",
              " 'забава',\n",
              " ',',\n",
              " 'бессонница',\n",
              " ',',\n",
              " 'лёгкий',\n",
              " 'вдохновение',\n",
              " ',',\n",
              " 'незрелый',\n",
              " 'и',\n",
              " 'увядший',\n",
              " 'год',\n",
              " ',',\n",
              " 'ум',\n",
              " 'холодный',\n",
              " 'наблюдение',\n",
              " 'и',\n",
              " 'сердце',\n",
              " 'горестный',\n",
              " 'замета',\n",
              " '.',\n",
              " 'глава',\n",
              " 'первый',\n",
              " 'и',\n",
              " 'жить',\n",
              " 'торопиться',\n",
              " ',',\n",
              " 'и',\n",
              " 'чувствовать',\n",
              " 'спешить',\n",
              " '.',\n",
              " 'князь',\n",
              " 'вяземский',\n",
              " '[',\n",
              " '2',\n",
              " ']',\n",
              " 'i',\n",
              " '«',\n",
              " 'мой',\n",
              " 'дядя',\n",
              " 'самый',\n",
              " 'честной',\n",
              " 'правило',\n",
              " ',',\n",
              " 'когда',\n",
              " 'не',\n",
              " 'в',\n",
              " 'шутка',\n",
              " 'занемочь',\n",
              " ',',\n",
              " 'он',\n",
              " 'уважать',\n",
              " 'себя',\n",
              " 'заставить',\n",
              " 'и',\n",
              " 'хороший',\n",
              " 'выдумать',\n",
              " 'не',\n",
              " 'мочь',\n",
              " '.',\n",
              " 'он',\n",
              " 'пример',\n",
              " 'другой',\n",
              " 'наука',\n",
              " ';',\n",
              " 'но',\n",
              " ',',\n",
              " 'бог',\n",
              " 'мой',\n",
              " ',',\n",
              " 'какой',\n",
              " 'скука',\n",
              " 'с',\n",
              " 'больной',\n",
              " 'сидеть',\n",
              " 'и',\n",
              " 'день',\n",
              " 'и',\n",
              " 'ночь',\n",
              " ',',\n",
              " 'не',\n",
              " 'отходить',\n",
              " 'ни',\n",
              " 'шаг',\n",
              " 'прочь',\n",
              " '!',\n",
              " 'какой',\n",
              " 'низкий',\n",
              " 'коварство',\n",
              " 'полуживой',\n",
              " 'забавлять',\n",
              " ',',\n",
              " 'он',\n",
              " 'подушка',\n",
              " 'поправлять',\n",
              " ',',\n",
              " 'печально',\n",
              " 'подносить',\n",
              " 'лекарство',\n",
              " ',',\n",
              " 'вздыхать',\n",
              " 'и',\n",
              " 'думать',\n",
              " 'про',\n",
              " 'себя',\n",
              " ':',\n",
              " 'когда',\n",
              " 'же',\n",
              " 'черта',\n",
              " 'взять',\n",
              " 'ты',\n",
              " '!',\n",
              " '»',\n",
              " 'ii',\n",
              " 'так',\n",
              " 'думать',\n",
              " 'молодой',\n",
              " 'повеса',\n",
              " ',',\n",
              " 'лететь',\n",
              " 'в',\n",
              " 'пыль',\n",
              " 'на',\n",
              " 'почтовый',\n",
              " ',',\n",
              " 'всевышний',\n",
              " 'воля',\n",
              " 'зевес',\n",
              " 'наследник',\n",
              " 'весь',\n",
              " 'свой',\n",
              " 'родный',\n",
              " '.',\n",
              " '—',\n",
              " 'друг',\n",
              " 'людмила',\n",
              " 'и',\n",
              " 'руслан',\n",
              " '!',\n",
              " 'с',\n",
              " 'герой']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw2pjBcGHHal"
      },
      "source": [
        "Чтобы снова собрать из этого, текст, просто сконкатенируем все получившиеся строки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "CsyRRp-HHEA_",
        "outputId": "b165afd5-0123-4f0f-f01a-10344562ddc7"
      },
      "source": [
        "' '.join(lemm_pymorph)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'he мыслить гордый свет забавить , внимание дружба возлюбя , хотеть бы я ты представить залог достойный ты , достойный душа прекрасный , святой исполнить мечта , поэзия живой и ясный , высокий дума и простота ; но так и быть – рука пристрастный принять собрание пёстрый глава , полусмешной , полупечальный , простонародный , идеальный , небрежный плод мой забава , бессонница , лёгкий вдохновение , незрелый и увядший год , ум холодный наблюдение и сердце горестный замета . глава первый и жить торопиться , и чувствовать спешить . князь вяземский [ 2 ] i « мой дядя самый честной правило , когда не в шутка занемочь , он уважать себя заставить и хороший выдумать не мочь . он пример другой наука ; но , бог мой , какой скука с больной сидеть и день и ночь , не отходить ни шаг прочь ! какой низкий коварство полуживой забавлять , он подушка поправлять , печально подносить лекарство , вздыхать и думать про себя : когда же черта взять ты ! » ii так думать молодой повеса , лететь в пыль на почтовый , всевышний воля зевес наследник весь свой родный . — друг людмила и руслан ! с герой'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTnTGyQoHQO1"
      },
      "source": [
        "## **Формирование выборки сырых данных**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G52qxx-eHa0G"
      },
      "source": [
        "Обернем наши предыдущие действия в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXzmV747HYK3"
      },
      "source": [
        "from string import punctuation\r\n",
        "\r\n",
        "def lemmatize(input_text):\r\n",
        "    tokens = nltk.word_tokenize(input_text)\r\n",
        "    normed_tokens = [morph.parse(s)[0].normal_form for s in tokens]\r\n",
        "    # исключим также стоп-слова - всякие предлоги, союзы и т.п.\r\n",
        "    normed_tokens = [word for word in normed_tokens if word not in nltk.corpus.stopwords.words(\"russian\")]\r\n",
        "    # а также знаки препинания\r\n",
        "    normed_tokens = [word for word in normed_tokens if word not in punctuation]\r\n",
        "    return ' '.join(normed_tokens)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlYz816AHm1v"
      },
      "source": [
        "Рассмотрим задачу бинарной классификации текстов. Возьмем Евгения Онегина и книжонку из серии Попаданец и попробуем подобрать такой алгоритм, который смог бы их отличать друг от друга."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awKYdgWKHi0w",
        "outputId": "b3611209-6390-459f-8749-0b6abe8df0cb"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "# подготовим пустой датафрейм\r\n",
        "df = pd.DataFrame(columns=['text', 'class'])\r\n",
        "\r\n",
        "# это папки, в которых лежат файлы с текстами\r\n",
        "dir0 = \"Onegin\"\r\n",
        "dir1 = \"popadanec\"\r\n",
        "\r\n",
        "# считаем все наши тексты в датафрейм с указанием класса\r\n",
        "for filename in os.listdir(dir0):\r\n",
        "    with open(os.path.join(dir0, filename), encoding='utf8') as file:\r\n",
        "        contents = lemmatize(file.read())\r\n",
        "    df = df.append(pd.Series({'text': contents, 'class': 0}), ignore_index=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAR_DLLdH6ym"
      },
      "source": [
        "# и для второй папки тоже\r\n",
        "for filename in os.listdir(dir1):\r\n",
        "    with open(os.path.join(dir1, filename), encoding='utf8') as file:\r\n",
        "        contents = lemmatize(file.read())\r\n",
        "    df = df.append(pd.Series({'text': contents, 'class': 1}), ignore_index=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruc9o4jVIIX4"
      },
      "source": [
        "Посмотрим на вид нашего датафрейма"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "bxjNGH96IOLL",
        "outputId": "26eed5c2-3f57-4e1b-ea4f-1832ff7d6f76"
      },
      "source": [
        "df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>шалун заморозить пальчик больно смешно мать гр...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16 читатель помнить прелестный описание петерб...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>меж невидимый расти темнеть вечер синий пора о...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>томный волнение душа кровь тяжёлый умиление на...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>любить ричардсон прочесть грандисон ловлас пре...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>первый взгляд внутри корабль принципиально отл...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>крышка капсула медленно пойти вверх открывать ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>глава 4 сенсор настроить пассивный режим выдат...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>следующий номер план стоять покупка новый моде...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>самый главное это несмотря увеличение длина ст...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text class\n",
              "0   шалун заморозить пальчик больно смешно мать гр...     0\n",
              "1   16 читатель помнить прелестный описание петерб...     0\n",
              "2   меж невидимый расти темнеть вечер синий пора о...     0\n",
              "3   томный волнение душа кровь тяжёлый умиление на...     0\n",
              "4   любить ричардсон прочесть грандисон ловлас пре...     0\n",
              "..                                                ...   ...\n",
              "95  первый взгляд внутри корабль принципиально отл...     1\n",
              "96  крышка капсула медленно пойти вверх открывать ...     1\n",
              "97  глава 4 сенсор настроить пассивный режим выдат...     1\n",
              "98  следующий номер план стоять покупка новый моде...     1\n",
              "99  самый главное это несмотря увеличение длина ст...     1\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMAaObNVIalA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['class'], test_size=0.12, stratify=df['class'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbksd8xYItw2"
      },
      "source": [
        "# Bag-of-Words-эмбеддинг\r\n",
        "Pаботать с чистым текстом математические методы не умеют. Настало время получить эмбеддинги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIyrscsDIqam"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "bof_vect = CountVectorizer()\r\n",
        "bof_vect.fit(np.hstack([X_train, X_test]))\r\n",
        "bof_train = bof_vect.transform(X_train)\r\n",
        "bof_test = bof_vect.transform(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vk44q3MI2hk",
        "outputId": "c5aad8ef-0859-470e-ff74-84daf8b60f4e"
      },
      "source": [
        "bof_train.toarray()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajArKm_sI5fQ",
        "outputId": "37b03087-cc2c-41f0-92a7-bb6ed76a729f"
      },
      "source": [
        "bof_train.toarray().shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 10101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyPaI704I-oW"
      },
      "source": [
        "# TF-IDF-эмбеддинг"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnQerZ-qI8fl"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "tfidf_vect = TfidfVectorizer()\r\n",
        "tfidf_vect.fit(np.hstack([X_train, X_test]))\r\n",
        "tfidf_train = tfidf_vect.transform(X_train)\r\n",
        "tfidf_test = tfidf_vect.transform(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YK5iBC0JBxe",
        "outputId": "325c0393-2bc5-4579-ebfe-a0bb8d4a95bd"
      },
      "source": [
        "tfidf_train.toarray()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s2k67rjJ4Cm",
        "outputId": "d877c0b2-29f5-4a25-dffc-c72d528f1982"
      },
      "source": [
        "tfidf_train.toarray().shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 10101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PamPmK-J9zu"
      },
      "source": [
        "# Word2vec-эмбеддинг\r\n",
        "Поскольку w2v - это не sklearn'овский классификатор, он на выходе выдаст данные немного другого вида, и это надо будет учитывать в дальнейшей работе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl1yeejWKAU2"
      },
      "source": [
        "from gensim.models import Word2Vec\r\n",
        "X_train_w2v = X_train.apply(str.split)\r\n",
        "X_test_w2v = X_test.apply(str.split)\r\n",
        "w2v_vect = Word2Vec(np.hstack([X_train_w2v, X_test_w2v]), size=300, min_count=10, workers=8)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPdMptsJKC-n",
        "outputId": "086d492b-64db-4aab-dfdc-1d11633644b5"
      },
      "source": [
        "X_train_w2v"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    [xiii, ленский, иметь, охота, уза, брак, несть...\n",
              "80    [—, лейтенант-коммандер, —, уточнить, я., это,...\n",
              "60    [хрен, сколько, тысячелетие, сильно, большой, ...\n",
              "31    [усеять, плошка, кругом, блестеть, великолепны...\n",
              "81    [платформа, представлять, круг, диаметр, метр,...\n",
              "                            ...                        \n",
              "46    [весна, клик, лебединый, близ, вода, сиять, ти...\n",
              "62    [знак, свой, беспомощность, развести, сторона,...\n",
              "78    [ива, остановить, жест, —, спасибо, легат, цен...\n",
              "18    [мы…, ничто, блестеть, рада, простодушно, посе...\n",
              "90    [склонить, голова, ответный, поклон, —, честь,...\n",
              "Name: text, Length: 88, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAeNRU81Jo_u"
      },
      "source": [
        "С ворд-ту-веком можно делать разные интересные вещи. Например, следующей командой мы можем вывести слова, которые оказались наиболее близкими по значению к заданному слову на обучающей выборке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pi3R9HhJkOa",
        "outputId": "fe0a6e68-58f9-49ee-a9fd-e0e426af8e82"
      },
      "source": [
        "w2v_vect.most_similar(positive=\"человек\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ещё', 0.9999793171882629),\n",
              " ('весь', 0.99997878074646),\n",
              " ('всё', 0.9999784231185913),\n",
              " ('это', 0.9999773502349854),\n",
              " ('—', 0.9999769926071167),\n",
              " ('свой', 0.9999765157699585),\n",
              " ('корабль', 0.9999746084213257),\n",
              " ('мочь', 0.9999736547470093),\n",
              " ('душа', 0.9999731183052063),\n",
              " ('год', 0.9999727010726929)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg7d40KfKw5s"
      },
      "source": [
        "Преобразуем тексты в вектора - возьмем сумму векторов всех слов, которые входят в текст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biCBgG_mKsQs",
        "outputId": "5ead0664-f1f7-4901-cb65-5ce681a04377"
      },
      "source": [
        "def text2vec(text):\r\n",
        "    \"\"\"Усредняем векторы слов\"\"\"\r\n",
        "    vecs = []\r\n",
        "    for word in text:\r\n",
        "        try:\r\n",
        "            vecs.append(w2v_vect[word])\r\n",
        "        except KeyError:\r\n",
        "            pass\r\n",
        "    return np.sum(vecs, axis=0) / len(vecs)\r\n",
        "\r\n",
        "w2v_train = X_train_w2v.apply(text2vec)\r\n",
        "w2v_test = X_test_w2v.apply(text2vec)\r\n",
        "w2v_train"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    [0.096241556, -0.14170004, -0.057885505, -0.05...\n",
              "80    [0.10327929, -0.15214378, -0.06206952, -0.0552...\n",
              "60    [0.10208867, -0.15050392, -0.061551485, -0.054...\n",
              "31    [0.08031369, -0.118201785, -0.048475277, -0.04...\n",
              "81    [0.088913046, -0.13082908, -0.053259987, -0.04...\n",
              "                            ...                        \n",
              "46    [0.08086777, -0.11894336, -0.04872365, -0.0433...\n",
              "62    [0.09612576, -0.14146197, -0.05774134, -0.0516...\n",
              "78    [0.09840897, -0.1447756, -0.05923165, -0.05275...\n",
              "18    [0.101684034, -0.15004024, -0.061538562, -0.05...\n",
              "90    [0.08716605, -0.1285638, -0.052426126, -0.0468...\n",
              "Name: text, Length: 88, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjdg5sLeK03U",
        "outputId": "e14056a5-fc6c-4d38-fd0e-7d58bc37307d"
      },
      "source": [
        "w2v_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "fqtCadv1K3x6",
        "outputId": "44c9aadd-b989-4e37-de69-de5daab94d47"
      },
      "source": [
        "w2v_train[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c7703dd06ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9du2aR_K50p",
        "outputId": "a49e9461-069f-4333-ddfd-ae477b89e439"
      },
      "source": [
        "w2v_train = np.dstack(w2v_train)[0]\r\n",
        "w2v_train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 88)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0VdfhB-LD0s"
      },
      "source": [
        "w2v_test = np.dstack(w2v_test)[0]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP-WTkb5LNXx"
      },
      "source": [
        "# Классификация текстов\r\n",
        "Теперь у нас есть классическое признаковое описание каждого текста. Можем обучать классификаторы или придумать еще какую-то метрику.\r\n",
        "\r\n",
        "Давайте вычислим для каждого эмбеддинга по два суммарных вектора Для Bag of Words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekQO7dZfLGfu",
        "outputId": "16a0ce8a-d3a8-4962-d81d-e223b1f93d7e"
      },
      "source": [
        "b=y_train == 0\r\n",
        "a=bof_train[b[len(b)]]\r\n",
        "oneg_mean_bof = np.sum(a, axis=0)\r\n",
        "oneg_mean_bof.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuofAoI7RcD2"
      },
      "source": [
        "d=y_train == 1\r\n",
        "c=bof_train[d[len(d)]]\r\n",
        "pop_mean_bof = np.sum(c, axis=0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8ENEW9XRjJL"
      },
      "source": [
        "Для TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myRtdf6RRdpZ",
        "outputId": "d59f664c-79eb-4676-ef76-4c74ab8f6489"
      },
      "source": [
        "b=y_train == 0\r\n",
        "a=tfidf_train[b[len(b)]]\r\n",
        "oneg_mean_tfidf = np.sum(a, axis=0)\r\n",
        "oneg_mean_tfidf.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9mX1Pt7Rl_h"
      },
      "source": [
        "d=y_train == 1\r\n",
        "c=tfidf_train[d[len(d)]]\r\n",
        "pop_mean_tfidf = np.sum(c, axis=0)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFAuVZaBRpT-"
      },
      "source": [
        "Для Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV5m53__Rnwp",
        "outputId": "41998fb9-9b77-4cb6-8a9c-8784d2c5387e"
      },
      "source": [
        "oneg_mean_w2v = np.sum(w2v_train[:, y_train == 1], axis=1)\r\n",
        "oneg_mean_w2v.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrWQFisiRrhN"
      },
      "source": [
        "pop_mean_w2v = np.sum(w2v_train[:, y_train == 0], axis=1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QmNih5SSS64"
      },
      "source": [
        "Посмотрим на их вид:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rICcQjMkSRBx",
        "outputId": "e4033ba8-8946-47f3-cf74-b56bf4f1f937"
      },
      "source": [
        "oneg_mean_bof"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TxlKFhLSVy6",
        "outputId": "4003577e-edb8-484d-c67c-ef5d2f7e0089"
      },
      "source": [
        "oneg_mean_tfidf"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtE6oQ8SSY81",
        "outputId": "bf5d093f-84be-474a-c79d-aa605968cdff"
      },
      "source": [
        "oneg_mean_w2v"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  4.297532  ,  -6.3319516 ,  -2.5813491 ,  -2.3018336 ,\n",
              "        -5.175403  ,  -4.3950944 ,   4.9457664 ,  -5.03447   ,\n",
              "         4.3867345 ,   1.0973651 ,  -1.1242104 ,   8.487882  ,\n",
              "         0.8259996 ,  -4.703243  ,  -5.723107  , -13.366727  ,\n",
              "        -2.3294013 ,   4.043012  ,  -4.7797093 ,  -6.0962663 ,\n",
              "        -2.8844419 ,   2.0650856 ,   4.367884  ,  13.134641  ,\n",
              "         3.1744232 ,  -2.6749132 ,   0.34669584,   3.9526758 ,\n",
              "         5.2513046 , -14.059929  ,  -2.6032097 ,   3.5150933 ,\n",
              "         0.06490763,   3.7994895 ,   9.239856  ,  -6.631697  ,\n",
              "         0.4333183 ,   3.4581356 ,   1.1223385 , -15.98746   ,\n",
              "        -6.0669813 ,  -6.758249  ,   1.0637025 ,  -1.4383658 ,\n",
              "         7.9644117 , -10.411005  ,  -2.5322297 , -12.239351  ,\n",
              "         4.3995614 ,  -5.702172  ,  -5.207567  ,   1.6836512 ,\n",
              "        -7.4332542 ,  -7.339035  ,   7.1731744 ,   3.6311154 ,\n",
              "        11.9297495 ,   4.8779807 ,  -6.459734  ,   7.4495134 ,\n",
              "         9.328403  ,  -4.973703  ,  12.565379  ,  -7.012962  ,\n",
              "        -2.3212183 ,   1.9847963 ,   2.5962734 ,  -7.6374035 ,\n",
              "         2.5392542 ,   3.1585782 ,   1.655874  ,  -5.6962094 ,\n",
              "         0.27444988,   4.1336846 ,  10.791118  ,  -3.5244877 ,\n",
              "        -7.576413  , -10.010609  ,   8.271111  ,   3.2066987 ,\n",
              "        -2.2661493 ,  -2.6127841 ,  -3.3169997 ,  -2.1638541 ,\n",
              "         1.8872315 ,   2.077422  ,   2.850886  ,  -9.258282  ,\n",
              "        -2.2114244 ,   2.1331003 ,  -2.4554687 ,  -2.074037  ,\n",
              "         7.1068296 ,  -4.282953  ,  -2.3977544 ,  -1.423141  ,\n",
              "         7.0976872 ,   3.645926  ,   0.45077875,  -4.106675  ,\n",
              "         7.243799  ,   1.8378133 ,   0.3935275 ,   2.1637535 ,\n",
              "       -12.875403  ,   3.180787  ,  -7.8442216 ,   3.9991138 ,\n",
              "        -4.498954  ,  -2.1100862 ,  10.11132   ,  -3.858047  ,\n",
              "        -4.058329  ,   1.0151263 ,   1.6932403 ,  -4.2556334 ,\n",
              "         0.55133855,   1.3817431 ,   3.6342785 ,  -1.9877532 ,\n",
              "        -7.835416  ,  -2.1694098 ,   4.9904323 ,   9.471313  ,\n",
              "        -4.2631283 ,  -1.1271464 ,   1.5364364 ,  -7.375504  ,\n",
              "        -0.43787658,   4.574982  ,   4.7921524 ,   0.41042247,\n",
              "        -0.63343793,   4.505797  , -12.166211  ,  -0.89652514,\n",
              "         2.155855  ,  -4.200054  ,   9.398767  ,  11.101186  ,\n",
              "        -1.9030224 ,   0.8887861 ,   0.7682254 ,  10.815776  ,\n",
              "        -0.3945232 ,   8.769248  ,   0.6267042 ,  -1.0531558 ,\n",
              "        -0.9119055 ,  -2.1728644 ,  -2.672531  ,   3.8045769 ,\n",
              "        -3.7548854 ,   2.3033187 ,  -1.9835044 ,   4.1324983 ,\n",
              "         1.4916512 ,   6.3671927 ,   4.4862514 ,  -1.928386  ,\n",
              "         4.5339794 ,   0.769715  ,   2.0924056 ,  -1.094598  ,\n",
              "        -6.562472  ,  -0.3562253 ,   7.9548645 ,  -6.0357213 ,\n",
              "        -1.8791537 ,  -4.1392913 ,  -4.49494   ,  -6.351244  ,\n",
              "         9.253273  ,   2.0456214 ,  -4.015352  ,   3.3769069 ,\n",
              "        11.224255  ,  -4.623632  ,   1.7398438 ,   4.332014  ,\n",
              "        -3.298478  ,  -6.742831  ,   6.547302  ,  -4.0582237 ,\n",
              "         0.70326   ,   3.955582  ,  -4.3953013 ,   5.812743  ,\n",
              "         2.063419  ,  -4.2000365 ,  -3.863365  ,  -6.732415  ,\n",
              "        -4.6611686 ,  -3.004256  ,  -6.380591  ,  -4.751539  ,\n",
              "        -1.9752399 ,  -5.460666  ,  -1.9261361 ,   6.9780216 ,\n",
              "         6.078788  ,   0.8145953 ,   7.9331164 ,  -2.8671217 ,\n",
              "         0.05892299, -11.726582  ,   3.4261835 , -10.188662  ,\n",
              "        -0.6108432 ,  -2.3959293 ,  -2.2637763 ,   9.38179   ,\n",
              "         3.575807  ,   2.989133  ,  -8.170491  ,  -5.469241  ,\n",
              "        -1.6210918 ,   9.594252  ,   1.1829934 ,   7.053467  ,\n",
              "        -4.9181933 ,  -0.5795935 ,  -2.4827719 ,  -4.562869  ,\n",
              "       -10.367618  ,   3.223209  ,  -7.657388  ,   1.5033251 ,\n",
              "        -5.4821153 ,   1.2498335 ,   3.5085998 ,   4.1728234 ,\n",
              "        -0.04335481,   0.661501  ,   9.30333   ,  -4.375994  ,\n",
              "         0.8560594 ,  -1.2676684 ,   2.2728996 ,  -1.110714  ,\n",
              "         3.6955419 ,  -4.9597545 ,   6.775733  ,  -2.4451482 ,\n",
              "         1.362345  ,   4.9188247 ,   7.3117023 ,   1.6024683 ,\n",
              "         6.717038  ,  14.923022  ,   2.0893245 ,  -6.49838   ,\n",
              "         0.36088285,  -3.1543367 ,  -3.5909855 ,   3.5884347 ,\n",
              "         1.9038473 ,   6.901336  ,   2.4509807 ,   1.1827453 ,\n",
              "        12.719345  ,  -1.5011529 ,  -3.9058802 ,   4.137637  ,\n",
              "         5.118671  ,  -2.9750123 ,  -1.9751579 ,   4.1325364 ,\n",
              "        -3.82684   ,   1.3140903 ,  -3.3133023 ,   0.8026258 ,\n",
              "         0.38694766,  -4.2730503 ,  -2.1680932 ,   0.06501341,\n",
              "        -3.1745472 ,  -7.2356296 ,  -3.2608688 ,   7.922889  ,\n",
              "         4.645476  ,  -1.245282  ,  -1.6457465 ,   3.1228125 ,\n",
              "         1.048006  ,   0.2794692 ,   6.220929  ,  -7.231739  ,\n",
              "         4.845883  ,  -3.9546738 ,   2.5091672 ,  -1.6473694 ,\n",
              "         1.9523454 ,   3.789197  ,   3.4526143 ,  -1.9074794 ,\n",
              "        -9.508699  ,  -1.0850097 ,  -2.3376727 ,  -2.6521804 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9B6A2gJSfxO"
      },
      "source": [
        "А теперь построим датафреймы с результатами классификации тестовых текстов. Будем считать, что текст относится к тому исполнителю, с которым его косинусное расстояние больше."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CxRhyNyScTv"
      },
      "source": [
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "vNPGQ3XeSiI1",
        "outputId": "5ee9d23e-525e-4492-b1fe-0cad5a310b5e"
      },
      "source": [
        "bof_oneg = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=oneg_mean_bof)\r\n",
        "bof_pop = np.apply_along_axis(cosine, 1, bof_test.toarray(), v=pop_mean_bof)\r\n",
        "\r\n",
        "bof_results = pd.DataFrame([\r\n",
        "    bof_oneg,\r\n",
        "    bof_pop,\r\n",
        "    np.maximum(bof_oneg, bof_pop) == bof_pop,\r\n",
        "    y_test\r\n",
        "], index=[\"oneg\", \"pop\", \"predict\", \"class\"]).T.astype(np.float)\r\n",
        "bof_results"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>oneg</th>\n",
              "      <th>pop</th>\n",
              "      <th>predict</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.800688</td>\n",
              "      <td>0.822247</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.810771</td>\n",
              "      <td>0.788585</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.695865</td>\n",
              "      <td>0.806193</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.808818</td>\n",
              "      <td>0.857083</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.861201</td>\n",
              "      <td>0.756087</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.893243</td>\n",
              "      <td>0.683191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.885262</td>\n",
              "      <td>0.655895</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.887680</td>\n",
              "      <td>0.725245</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.761994</td>\n",
              "      <td>0.862498</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.893427</td>\n",
              "      <td>0.778873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.907589</td>\n",
              "      <td>0.755878</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.755837</td>\n",
              "      <td>0.846417</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        oneg       pop  predict  class\n",
              "0   0.800688  0.822247      1.0    0.0\n",
              "1   0.810771  0.788585      0.0    0.0\n",
              "2   0.695865  0.806193      1.0    0.0\n",
              "3   0.808818  0.857083      1.0    0.0\n",
              "4   0.861201  0.756087      0.0    1.0\n",
              "5   0.893243  0.683191      0.0    1.0\n",
              "6   0.885262  0.655895      0.0    1.0\n",
              "7   0.887680  0.725245      0.0    1.0\n",
              "8   0.761994  0.862498      1.0    0.0\n",
              "9   0.893427  0.778873      0.0    1.0\n",
              "10  0.907589  0.755878      0.0    1.0\n",
              "11  0.755837  0.846417      1.0    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB94pCFQS01P",
        "outputId": "e26288d3-c580-4e1f-9dc0-afb0873d8a70"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "accuracy_score(bof_results['predict'], bof_results['class'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "P0URXPG4S6CB",
        "outputId": "d150a578-b50a-4583-e4ad-843c5a48bb86"
      },
      "source": [
        "tfidf_oneg = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=oneg_mean_tfidf)\r\n",
        "tfidf_pop = np.apply_along_axis(cosine, 1, tfidf_test.toarray(), v=pop_mean_tfidf)\r\n",
        "\r\n",
        "tfidf_results = pd.DataFrame([\r\n",
        "    tfidf_oneg,\r\n",
        "    tfidf_pop,\r\n",
        "    np.maximum(tfidf_oneg, tfidf_pop) == tfidf_pop,\r\n",
        "    y_test\r\n",
        "], index=[\"oneg\", \"pop\", \"predict\", \"class\"]).T.astype(np.float)\r\n",
        "tfidf_results"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>oneg</th>\n",
              "      <th>pop</th>\n",
              "      <th>predict</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.919880</td>\n",
              "      <td>0.958795</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.933467</td>\n",
              "      <td>0.947197</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.859463</td>\n",
              "      <td>0.943444</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.927808</td>\n",
              "      <td>0.962522</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.954390</td>\n",
              "      <td>0.911063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.964623</td>\n",
              "      <td>0.899351</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.963830</td>\n",
              "      <td>0.891864</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.975720</td>\n",
              "      <td>0.880890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.879697</td>\n",
              "      <td>0.946846</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.967019</td>\n",
              "      <td>0.916600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.975076</td>\n",
              "      <td>0.927974</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.885697</td>\n",
              "      <td>0.966178</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        oneg       pop  predict  class\n",
              "0   0.919880  0.958795      1.0    0.0\n",
              "1   0.933467  0.947197      1.0    0.0\n",
              "2   0.859463  0.943444      1.0    0.0\n",
              "3   0.927808  0.962522      1.0    0.0\n",
              "4   0.954390  0.911063      0.0    1.0\n",
              "5   0.964623  0.899351      0.0    1.0\n",
              "6   0.963830  0.891864      0.0    1.0\n",
              "7   0.975720  0.880890      0.0    1.0\n",
              "8   0.879697  0.946846      1.0    0.0\n",
              "9   0.967019  0.916600      0.0    1.0\n",
              "10  0.975076  0.927974      0.0    1.0\n",
              "11  0.885697  0.966178      1.0    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dkHR8rOTK3o",
        "outputId": "7574c84c-d4af-4f09-a125-948ebf7d4083"
      },
      "source": [
        "accuracy_score(tfidf_results['predict'], tfidf_results['class'])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "dyZN1lfXTNrl",
        "outputId": "ad58e951-7547-46fc-a32d-a7c578b2c531"
      },
      "source": [
        "w2v_oneg = np.apply_along_axis(cosine, 0, w2v_test, v=oneg_mean_w2v)\r\n",
        "w2v_pop = np.apply_along_axis(cosine, 0, w2v_test, v=pop_mean_w2v)\r\n",
        "\r\n",
        "w2v_results = pd.DataFrame([\r\n",
        "    w2v_oneg,\r\n",
        "    w2v_pop,\r\n",
        "    np.maximum(w2v_oneg, w2v_pop) == w2v_pop,\r\n",
        "    y_test\r\n",
        "], index=[\"oneg\", \"pop\", \"predict\", \"class\"]).T.astype(np.float)\r\n",
        "w2v_results"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>oneg</th>\n",
              "      <th>pop</th>\n",
              "      <th>predict</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.311302e-06</td>\n",
              "      <td>2.980232e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.609325e-06</td>\n",
              "      <td>5.364418e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.132488e-06</td>\n",
              "      <td>2.980232e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.536743e-07</td>\n",
              "      <td>4.172325e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.384186e-07</td>\n",
              "      <td>1.549721e-06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.384186e-07</td>\n",
              "      <td>1.728535e-06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.788139e-07</td>\n",
              "      <td>1.251698e-06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.576279e-07</td>\n",
              "      <td>1.609325e-06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.668930e-06</td>\n",
              "      <td>4.172325e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.980232e-07</td>\n",
              "      <td>1.251698e-06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.172325e-07</td>\n",
              "      <td>1.490116e-06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.490116e-06</td>\n",
              "      <td>4.768372e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            oneg           pop  predict  class\n",
              "0   1.311302e-06  2.980232e-07      0.0    0.0\n",
              "1   1.609325e-06  5.364418e-07      0.0    0.0\n",
              "2   1.132488e-06  2.980232e-07      0.0    0.0\n",
              "3   9.536743e-07  4.172325e-07      0.0    0.0\n",
              "4   2.384186e-07  1.549721e-06      1.0    1.0\n",
              "5   2.384186e-07  1.728535e-06      1.0    1.0\n",
              "6   1.788139e-07  1.251698e-06      1.0    1.0\n",
              "7   3.576279e-07  1.609325e-06      1.0    1.0\n",
              "8   1.668930e-06  4.172325e-07      0.0    0.0\n",
              "9   2.980232e-07  1.251698e-06      1.0    1.0\n",
              "10  4.172325e-07  1.490116e-06      1.0    1.0\n",
              "11  1.490116e-06  4.768372e-07      0.0    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQp1FZ-GTRqM",
        "outputId": "25b6b81b-0be0-485c-800f-00bef32ae86d"
      },
      "source": [
        "accuracy_score(w2v_results['predict'], w2v_results['class'])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONQfpeyETgvc",
        "outputId": "3efaab85-1eb5-4732-e91a-417ba7a3c64a"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "RandomForestClassifier().fit(bof_train.toarray(), y_train.tolist()).score(bof_test.toarray(), y_test.tolist())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guM1ydkrTu3J",
        "outputId": "6d33e7a2-adc0-48fe-9f92-520df474d009"
      },
      "source": [
        "RandomForestClassifier().fit(tfidf_train.toarray(), y_train.tolist()).score(tfidf_test.toarray(), y_test.tolist())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMuI9uOqTwYq",
        "outputId": "c40cf4af-7459-43be-8fcb-d98cf243599f"
      },
      "source": [
        "RandomForestClassifier().fit(w2v_train.T, y_train.tolist()).score(w2v_test.T, y_test.tolist())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osLH0WdQTzRr"
      },
      "source": [
        "Ближайшие соседи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DVXcSGZTxsx",
        "outputId": "d10dcfd7-e9de-4c7f-dd45-c9ae43e36ba4"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "clf = KNeighborsClassifier(n_neighbors=10)\r\n",
        "clf.fit(bof_train.toarray(), y_train.tolist())\r\n",
        "clf.score(bof_test.toarray(), y_test.tolist())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9166666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVtM5Pk8Tzsp",
        "outputId": "563d7724-fdf0-4d9d-edc0-64e4836fe064"
      },
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=10)\r\n",
        "clf.fit(tfidf_train.toarray(), y_train.tolist())\r\n",
        "clf.score(tfidf_test.toarray(), y_test.tolist())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dDHkbB6T7DY",
        "outputId": "bcd06cb1-9375-4772-fa09-d9613a19c476"
      },
      "source": [
        "clf = KNeighborsClassifier(n_neighbors=10)\r\n",
        "clf.fit(w2v_train.T, y_train.tolist())\r\n",
        "clf.score(w2v_test.T, y_test.tolist())"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeKN2eVvUAc6"
      },
      "source": [
        "Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hydSatNyT87o",
        "outputId": "10d96762-4725-4de5-88db-a5be2c94631e"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "lo = LogisticRegression()\r\n",
        "lo.fit(bof_train.toarray(), y_train.tolist())\r\n",
        "lo.score(bof_test.toarray(), y_test.tolist())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCo6X4ZtUBGs",
        "outputId": "2c7c7698-fb17-4757-841c-e9944809ed03"
      },
      "source": [
        "lo = LogisticRegression()\r\n",
        "lo.fit(tfidf_train.toarray(), y_train.tolist())\r\n",
        "lo.score(tfidf_test.toarray(), y_test.tolist())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmiqGmQYUFY-",
        "outputId": "10a05800-3e86-4fc8-96b0-33b441e26684"
      },
      "source": [
        "lo = LogisticRegression()\r\n",
        "lo.fit(w2v_train.T, y_train.tolist())\r\n",
        "lo.score(w2v_test.T, y_test.tolist())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLq8RovEUJ84"
      },
      "source": [
        "По итогу, обычные методы классификации показывают результат лучше."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJDTZ-6pUKtV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}